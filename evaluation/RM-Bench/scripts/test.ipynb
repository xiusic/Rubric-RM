{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xiusic/RM-Bench/results/Gen_RMs/unhacked_flexible_step33/total_dataset_global_step33_hf_REWORD_MODEL_20250318_172310.json\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "def split_dataset_by_domain(dataset: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    domains = [\"chat\",\"math\",\"code\",\"safety\"]\n",
    "    domain_dataset_dict = {}\n",
    "    for domain in domains:\n",
    "        domain_dataset_dict[domain] = [example for example in dataset if example['domain'].startswith(domain)]\n",
    "    \n",
    "    # pop the domain keys\n",
    "    for domain in domain_dataset_dict:\n",
    "        for example in domain_dataset_dict[domain]:\n",
    "            example.pop('domain')\n",
    "    \n",
    "    return domain_dataset_dict\n",
    "\n",
    "\n",
    "def compute_accuracy_gen(results: List[Dict[str, Any]]) -> Dict[str, float]:\n",
    "    if 'domain' in results[0]:\n",
    "        # this indicates this is total_dataset.json\n",
    "        print('We are handling total_dataset.json')\n",
    "        print('Splitting the dataset by domain...')\n",
    "        # thus we need to split the results into different domains\n",
    "        split_results = split_dataset_by_domain(results)\n",
    "        domain_results = {}\n",
    "        for domain in split_results:\n",
    "            domain_results[domain] = compute_accuracy_gen(split_results[domain])\n",
    "        domain_avg_results = {}\n",
    "        for domain in domain_results:\n",
    "            domain_avg_results[domain] = np.mean(list(domain_results[domain].values()))\n",
    "        domain_hard_normal_easy_acc = {\n",
    "            \"hard_acc\": np.mean([domain_results[domain][\"hard_acc\"] for domain in domain_results]),\n",
    "            \"normal_acc\": np.mean([domain_results[domain][\"normal_acc\"] for domain in domain_results]),\n",
    "            \"easy_acc\": np.mean([domain_results[domain][\"easy_acc\"] for domain in domain_results])\n",
    "        }\n",
    "        total_avg_acc = np.mean([domain_avg_results[domain] for domain in domain_avg_results])\n",
    "        # merge the results into one falten dictionary\n",
    "        final_results = {}\n",
    "        # merge domain_avg_results into final_results\n",
    "        final_results.update(domain_avg_results)\n",
    "        # merge domain_hard_normal_easy_acc into final_results\n",
    "        final_results.update(domain_hard_normal_easy_acc)\n",
    "        # merge total_avg_acc into final_results\n",
    "        final_results.update({\"total_avg_acc\": total_avg_acc})\n",
    "        return final_results\n",
    "            \n",
    "    \n",
    "    # results is a list of dictionaries, each dictionary contains the following keys:\n",
    "    # score_chosen: [float, float, float], the scores of the chosen responses\n",
    "    # score_rejected: [float, float, float], the scores of the rejected responses\n",
    "    # the scores are in the order of [concise, detailed_plain, detailed_markdown]\n",
    "    # we will compare the scores of chosen responses and rejected responses iteratively\n",
    "    # formatted as a 3x3 matrix, where the rows represent the scores of chosen responses\n",
    "    # and the columns represent the scores of rejected responses\n",
    "    MATRIX_SIZE = 3 # the column and row size of the matrix\n",
    "    acc_matrix = np.zeros((MATRIX_SIZE, MATRIX_SIZE))\n",
    "    for result in results:\n",
    "        for i in range(len(result[\"result\"])):\n",
    "            for j in range(len(result[\"result\"])):\n",
    "                if result[\"result\"][i] == 1:\n",
    "                    acc_matrix[i][j] += 1\n",
    "    \n",
    "    # compute the accuracy by dividing the number of correct comparisons by the total number of comparisons\n",
    "    acc_matrix /= len(results)\n",
    "    # compute the hard,normal,easy accuracy\n",
    "    # hard accuracy: the average of the upper-right triangle of the matrix\n",
    "    # namely chosen responses with less fancy style compared to rejected responses with more fancy style\n",
    "    upper_right_count = MATRIX_SIZE * (MATRIX_SIZE - 1) / 2\n",
    "    hard_acc = np.sum(np.triu(acc_matrix, 1)) / upper_right_count\n",
    "    # normal accuracy: the average of the diagonal of the matrix\n",
    "    # namely chosen responses with the same style compared to rejected responses with the same style\n",
    "    normal_acc = np.mean(np.diag(acc_matrix))\n",
    "    # easy accuracy: the average of the lower-left triangle of the matrix\n",
    "    # namely chosen responses with more fancy style compared to rejected responses with less fancy style\n",
    "    lower_left_count = MATRIX_SIZE * (MATRIX_SIZE - 1) / 2\n",
    "    easy_acc = np.sum(np.tril(acc_matrix, -1)) / lower_left_count\n",
    "    \n",
    "    return {\n",
    "        \"hard_acc\": hard_acc,\n",
    "        \"normal_acc\": normal_acc,\n",
    "        \"easy_acc\": easy_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are handling total_dataset.json\n",
      "Splitting the dataset by domain...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat': 0.6563307493540051,\n",
       " 'math': 0.5803402646502835,\n",
       " 'code': 0.5014619883040936,\n",
       " 'safety': 0.9342403628117913,\n",
       " 'hard_acc': 0.6730477505536333,\n",
       " 'normal_acc': 0.6680933412800434,\n",
       " 'easy_acc': 0.6631389320064536,\n",
       " 'total_avg_acc': 0.6680933412800434}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy_gen(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy, normal, hard, total = 0, 0, 0, 0\n",
    "for item in data:\n",
    "    res = item['result']\n",
    "    if res[0] == 1:\n",
    "        easy += 1 \n",
    "    if res[1] == 1:\n",
    "        normal += 1 \n",
    "    if res[2] == 1:\n",
    "        hard += 1 \n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917, 919, 918, 1327)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy, normal, hard, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6910324039186134"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "917/1327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691785983421251"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(917 + 919 + 918) / (1327 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
